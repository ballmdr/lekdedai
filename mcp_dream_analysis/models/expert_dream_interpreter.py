"""
Expert Dream Interpreter - ‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå AI ‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ù‡∏±‡∏ô
Advanced AI system for Thai dream interpretation based on ancient knowledge
"""
import numpy as np
import re
import json
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import logging

try:
    from pythainlp import word_tokenize, sent_tokenize
    from pythainlp.util import normalize
    PYTHAINLP_AVAILABLE = True
except ImportError:
    PYTHAINLP_AVAILABLE = False

class ExpertDreamInterpreter:
    """
    ‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå AI ‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ù‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏£‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÑ‡∏ó‡∏¢
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # Ancient Thai Dream Knowledge Base
        self.knowledge_base = self._load_ancient_knowledge()
        
        # Context analysis patterns - ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î
        self.emotion_patterns = {
            'fear': r'‡∏Å‡∏•‡∏±‡∏ß|‡∏ï‡∏Å‡πÉ‡∏à|‡∏´‡∏ô‡∏µ|‡∏ß‡∏¥‡πà‡∏á‡∏´‡∏ô‡∏µ|‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏™|‡∏ô‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ß|‡∏Ç‡∏ô‡∏´‡∏±‡∏ß‡∏•‡∏∏‡∏Å|‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏•‡∏±‡∏ß|‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ß|‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏±‡∏ß',
            'joy': r'‡∏î‡∏µ‡πÉ‡∏à|‡∏™‡∏∏‡∏Ç|‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏≤‡∏∞|‡∏¢‡∏¥‡πâ‡∏°|‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç|‡∏™‡∏ô‡∏∏‡∏Å|‡πÄ‡∏û‡∏•‡∏¥‡∏ô|‡∏°‡πà‡∏ß‡∏¢‡∏î‡∏µ|‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°.*‡∏™‡∏∏‡∏Ç|‡∏£‡πà‡∏≤‡πÄ‡∏£‡∏¥‡∏á',
            'peaceful': r'‡∏™‡∏á‡∏ö|‡πÄ‡∏á‡∏µ‡∏¢‡∏ö|‡∏™‡∏á‡∏ö‡∏™‡∏∏‡∏Ç|‡∏ä‡∏∑‡πà‡∏ô‡πÉ‡∏à|‡∏™‡∏ö‡∏≤‡∏¢‡πÉ‡∏à|‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏≤‡∏¢|‡∏™‡∏á‡∏ö‡∏™‡∏∏‡∏Ç|‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏á‡∏ö|‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏ö‡∏≤‡∏¢',
            'aggressive': r'‡πÑ‡∏•‡πà|‡∏Å‡∏±‡∏î|‡πÇ‡∏à‡∏°‡∏ï‡∏µ|‡∏ó‡∏≥‡∏£‡πâ‡∏≤‡∏¢|‡∏ï‡πà‡∏≠‡∏™‡∏π‡πâ|‡∏£‡∏∏‡∏Å‡∏£‡∏≤‡∏ô|‡∏Ç‡πà‡∏°‡∏Ç‡∏π‡πà|‡∏Ç‡∏π‡πà|‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á|‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á|‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏∏',
            'protective': r'‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡∏£‡∏≠‡∏á|‡∏õ‡∏Å‡∏õ‡πâ‡∏≠‡∏á|‡∏ä‡πà‡∏ß‡∏¢|‡∏î‡∏π‡πÅ‡∏•|‡πÄ‡∏ù‡πâ‡∏≤|‡∏£‡∏±‡∏Å‡∏©‡∏≤|‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏±‡∏Å‡∏©‡∏≤|‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏µ|‡πÉ‡∏à‡∏î‡∏µ',
            'giving': r'‡πÉ‡∏´‡πâ|‡∏°‡∏≠‡∏ö|‡πÅ‡∏à‡∏Å|‡∏õ‡∏£‡∏∞‡∏ó‡∏≤‡∏ô|‡∏≠‡∏ß‡∏¢‡∏û‡∏£|‡∏™‡πà‡∏á‡∏°‡∏≠‡∏ö|‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏±‡∏ô|‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏à‡∏î‡∏µ|‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏µ',
            'losing': r'‡∏´‡∏≤‡∏¢|‡∏™‡∏π‡∏ç|‡πÄ‡∏™‡∏µ‡∏¢|‡∏´‡∏•‡πà‡∏ô|‡∏ï‡∏Å|‡∏Ç‡∏≤‡∏î|‡∏û‡∏•‡∏±‡∏î|‡∏™‡∏π‡∏ç‡∏´‡∏≤‡∏¢|‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à'
        }
        
        # Size and intensity modifiers - ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î
        self.size_patterns = {
            'huge': r'‡πÉ‡∏´‡∏ç‡πà‡∏°‡∏≤‡∏Å|‡∏¢‡∏±‡∏Å‡∏©‡πå|‡∏Ç‡∏ô‡∏≤‡∏î‡∏°‡∏´‡∏∂‡∏°‡∏≤|‡∏ï‡∏±‡∏ß‡πÇ‡∏ï|‡∏°‡πÇ‡∏´‡∏¨‡∏≤‡∏£|‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏´‡∏ç‡πà|‡∏°‡∏≤‡∏Å‡πÉ‡∏´‡∏ç‡πà|‡πÇ‡∏ï‡∏°‡∏≤‡∏Å',
            'big': r'‡πÉ‡∏´‡∏ç‡πà|‡πÇ‡∏ï|‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà|‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏´‡∏ç‡πà|‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏ç‡πà',
            'small': r'‡πÄ‡∏•‡πá‡∏Å|‡∏ô‡πâ‡∏≠‡∏¢|‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å|‡∏à‡∏¥‡πã‡∏ß|‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏•‡πá‡∏Å|‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡πá‡∏Å',
            'many': r'‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß|‡πÄ‡∏¢‡∏≠‡∏∞|‡∏°‡∏≤‡∏Å|‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å|‡∏ô‡∏±‡∏ö‡πÑ‡∏°‡πà‡∏ñ‡πâ‡∏ß‡∏ô|‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏¢‡∏≠‡∏∞|‡∏´‡∏•‡∏≤‡∏¢.*‡∏ï‡∏±‡∏ß',
            'beautiful': r'‡∏™‡∏ß‡∏¢|‡∏á‡∏≤‡∏°|‡∏ß‡∏¥‡∏à‡∏¥‡∏ï‡∏£|‡∏ô‡πà‡∏≤‡∏î‡∏π|‡∏™‡∏á‡πà‡∏≤|‡∏õ‡∏Å‡∏≤‡∏®‡∏±‡∏¢|‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏ß‡∏¢|‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°|‡∏¢‡πà‡∏≤‡∏á‡∏á‡∏≤‡∏°',
            'strange': r'‡πÅ‡∏õ‡∏•‡∏Å|‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥|‡∏õ‡∏£‡∏∞‡∏´‡∏•‡∏≤‡∏î|‡∏û‡∏¥‡∏®‡∏î‡∏≤‡∏£|‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏õ‡∏•‡∏Å|‡πÅ‡∏õ‡∏•‡∏Å.*‡∏î‡∏µ'
        }
    
    def _load_ancient_knowledge(self) -> Dict:
        """‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≥‡∏£‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ù‡∏±‡∏ô‡πÇ‡∏ö‡∏£‡∏≤‡∏ì"""
        return {
            # üêò ‡∏´‡∏°‡∏ß‡∏î‡∏™‡∏±‡∏ï‡∏ß‡πå
            'animals': {
                '‡∏Å‡∏ö': {'main': 8, 'secondary': 9, 'combinations': ['89', '59', '98', '95'], 'meaning': '‡πÇ‡∏ä‡∏Ñ‡∏•‡∏≤‡∏†‡∏à‡∏≤‡∏Å‡∏ô‡πâ‡∏≥'},
                '‡πÑ‡∏Å‡πà': {'main': 0, 'secondary': 9, 'combinations': ['09', '19', '90', '91'], 'meaning': '‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£‡∏î‡∏µ'},
                '‡∏Ñ‡∏ß‡∏≤‡∏¢': {'main': 4, 'secondary': 2, 'combinations': ['42', '82', '24', '28'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∏‡∏î‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå'},
                '‡∏á‡∏π': {'main': 5, 'secondary': 6, 'combinations': ['56', '65', '59', '95'], 'meaning': '‡∏û‡∏•‡∏±‡∏á‡∏•‡∏∂‡∏Å‡∏•‡∏±‡∏ö ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á'},
                '‡∏û‡∏¢‡∏≤‡∏ô‡∏≤‡∏Ñ': {'main': 8, 'secondary': 9, 'combinations': ['89', '98', '59', '95'], 'meaning': '‡∏û‡∏•‡∏±‡∏á‡∏®‡∏±‡∏Å‡∏î‡∏¥‡πå‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå'},
                '‡∏ä‡πâ‡∏≤‡∏á': {'main': 9, 'secondary': 1, 'combinations': ['91', '19', '90', '10'], 'meaning': '‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡∏ï‡∏¥‡∏¢‡∏® ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏á‡∏Ñ‡∏±‡πà‡∏á'},
                '‡πÄ‡∏™‡∏∑‡∏≠': {'main': 3, 'secondary': 4, 'combinations': ['34', '43', '30', '40'], 'meaning': '‡∏≠‡∏≥‡∏ô‡∏≤‡∏à ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏•‡πâ‡∏≤‡∏´‡∏≤‡∏ç'},
                '‡∏´‡∏°‡∏π': {'main': 2, 'secondary': 7, 'combinations': ['27', '72', '20', '70'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∏‡∏î‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå'},
                '‡∏´‡∏°‡∏≤': {'main': 4, 'secondary': 5, 'combinations': ['45', '54', '40', '50'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏á‡∏£‡∏±‡∏Å‡∏†‡∏±‡∏Å‡∏î‡∏µ'},
                '‡πÅ‡∏°‡∏ß': {'main': 6, 'secondary': 7, 'combinations': ['67', '76', '60', '70'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏à‡πâ‡∏≤‡πÄ‡∏•‡πà‡∏´‡πå'},
                '‡∏ß‡∏±‡∏ß': {'main': 0, 'secondary': 2, 'combinations': ['02', '20', '00', '22'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏¢‡∏±‡∏ô‡∏´‡∏°‡∏±‡πà‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏£'},
            },
            
            # üëë ‡∏´‡∏°‡∏ß‡∏î‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
            'people': {
                '‡∏Å‡∏©‡∏±‡∏ï‡∏£‡∏¥‡∏¢‡πå': {'main': 9, 'secondary': 5, 'combinations': ['59', '95', '19', '51'], 'meaning': '‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡∏ï‡∏¥‡∏¢‡∏®‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î'},
                '‡∏Ñ‡∏ô‡∏ï‡∏≤‡∏¢': {'main': 0, 'secondary': 4, 'combinations': ['04', '40', '07', '70'], 'meaning': '‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏´‡∏°‡πà'},
                '‡πÄ‡∏î‡πá‡∏Å‡∏ó‡∏≤‡∏£‡∏Å': {'main': 1, 'secondary': 3, 'combinations': ['11', '13', '33', '31'], 'meaning': '‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏´‡∏°‡πà'},
                '‡∏û‡∏£‡∏∞': {'main': 8, 'secondary': 9, 'combinations': ['89', '98', '80', '90'], 'meaning': '‡∏û‡∏£‡∏∞‡∏Ñ‡∏∏‡∏ì ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏®‡∏±‡∏Å‡∏î‡∏¥‡πå‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå'},
                '‡πÄ‡∏ì‡∏£': {'main': 9, 'secondary': 0, 'combinations': ['90', '09', '99', '00'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏£‡∏¥‡∏™‡∏∏‡∏ó‡∏ò‡∏¥‡πå'},
                '‡πÅ‡∏°‡πà': {'main': 2, 'secondary': 8, 'combinations': ['28', '82', '20', '80'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏°‡∏ï‡∏ï‡∏≤'},
                '‡∏û‡πà‡∏≠': {'main': 1, 'secondary': 9, 'combinations': ['19', '91', '10', '90'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡πÅ‡∏Ç‡πá‡∏á'},
            },
            
            # üè† ‡∏´‡∏°‡∏ß‡∏î‡∏™‡∏¥‡πà‡∏á‡∏Ç‡∏≠‡∏á / ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà
            'objects': {
                '‡πÄ‡∏á‡∏¥‡∏ô': {'main': 8, 'secondary': 2, 'combinations': ['28', '82', '68', '86'], 'meaning': '‡πÇ‡∏ä‡∏Ñ‡∏•‡∏≤‡∏†‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô'},
                '‡∏ó‡∏≠‡∏á': {'main': 8, 'secondary': 2, 'combinations': ['28', '82', '68', '86'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏á‡∏Ñ‡∏±‡πà‡∏á'},
                '‡∏ô‡πâ‡∏≥': {'main': 0, 'secondary': 2, 'combinations': ['02', '29', '32', '23'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∏‡∏î‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå'},
                '‡πÑ‡∏ü': {'main': 3, 'secondary': 7, 'combinations': ['37', '73', '30', '70'], 'meaning': '‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á'},
                '‡∏ß‡∏±‡∏î': {'main': 8, 'secondary': 0, 'combinations': ['80', '08', '88', '00'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏®‡∏±‡∏Å‡∏î‡∏¥‡πå‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå'},
                '‡∏ö‡πâ‡∏≤‡∏ô': {'main': 6, 'secondary': 8, 'combinations': ['68', '86', '60', '80'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á‡πÉ‡∏ô‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß'},
                '‡∏£‡∏ñ': {'main': 4, 'secondary': 0, 'combinations': ['40', '04', '44', '00'], 'meaning': '‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡πâ‡∏≤‡∏ß‡∏´‡∏ô‡πâ‡∏≤'},
            },
            
            # üé® ‡∏´‡∏°‡∏ß‡∏î‡∏™‡∏µ
            'colors': {
                '‡∏Ç‡∏≤‡∏ß': {'main': 9, 'secondary': 0, 'combinations': ['09', '90', '19', '91'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏£‡∏¥‡∏™‡∏∏‡∏ó‡∏ò‡∏¥‡πå ‡∏™‡∏á‡∏ö‡∏™‡∏∏‡∏Ç'},
                '‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß': {'main': 7, 'secondary': 3, 'combinations': ['73', '37', '03', '30'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏á‡∏≠‡∏Å‡∏á‡∏≤‡∏°'},
                '‡∏î‡∏≥': {'main': 0, 'secondary': 8, 'combinations': ['08', '80', '18', '81'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡∏•‡∏±‡∏ö ‡∏û‡∏•‡∏±‡∏á‡πÅ‡∏´‡πà‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô'},
                '‡πÅ‡∏î‡∏á': {'main': 5, 'secondary': 2, 'combinations': ['52', '25', '02', '20'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏Å ‡∏û‡∏•‡∏±‡∏á‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï'},
                '‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô': {'main': 6, 'secondary': 4, 'combinations': ['64', '46', '06', '60'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏á‡∏ö ‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£'},
                '‡∏ó‡∏≠‡∏á': {'main': 9, 'secondary': 1, 'combinations': ['91', '19', '99', '11'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏á‡∏Ñ‡∏±‡πà‡∏á ‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡∏ï‡∏¥‡∏¢‡∏®'},
                '‡πÄ‡∏á‡∏¥‡∏ô': {'main': 8, 'secondary': 2, 'combinations': ['82', '28', '88', '22'], 'meaning': '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏á‡∏Ñ‡∏±‡πà‡∏á‡πÅ‡∏•‡∏∞‡πÇ‡∏ä‡∏Ñ‡∏•‡∏≤‡∏†'},
            }
        }
    
    def interpret_dream(self, dream_text: str) -> Dict:
        """
        ‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå AI ‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ù‡∏±‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å‡∏ï‡∏≤‡∏°‡∏ï‡∏≥‡∏£‡∏≤‡πÇ‡∏ö‡∏£‡∏≤‡∏ì‡πÑ‡∏ó‡∏¢
        """
        try:
            # Normalize text
            if PYTHAINLP_AVAILABLE:
                dream_text = normalize(dream_text)
            
            # Extract context and emotions
            context = self._analyze_context(dream_text)
            
            # Find symbols in the dream
            symbols_found = self._find_symbols(dream_text)
            
            if not symbols_found:
                return self._handle_no_symbols_found(dream_text)
            
            # Generate interpretation
            interpretation = self._generate_interpretation(symbols_found, context)
            
            # Predict numbers with reasoning
            predicted_numbers = self._predict_numbers_with_reasoning(symbols_found, context)
            
            return {
                "interpretation": interpretation,
                "main_symbols": [symbol['name'] for symbol in symbols_found],
                "predicted_numbers": predicted_numbers,
                "context_analysis": context,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Dream interpretation error: {str(e)}")
            return self._get_fallback_response(dream_text, str(e))
    
    def _analyze_context(self, dream_text: str) -> Dict:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏ù‡∏±‡∏ô"""
        context = {
            'emotions': [],
            'size_modifiers': [],
            'interactions': []
        }
        
        text_lower = dream_text.lower()
        
        # Analyze emotions
        for emotion, pattern in self.emotion_patterns.items():
            if re.search(pattern, text_lower):
                context['emotions'].append(emotion)
        
        # Analyze size and intensity
        for size, pattern in self.size_patterns.items():
            if re.search(pattern, text_lower):
                context['size_modifiers'].append(size)
        
        return context
    
    def _find_symbols(self, dream_text: str) -> List[Dict]:
        """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡πÉ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ù‡∏±‡∏ô - ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"""
        symbols_found = []
        text_lower = dream_text.lower()
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥
        text_normalized = self._fix_thai_tokenization(text_lower)
        
        # Search in all categories
        for category, symbols in self.knowledge_base.items():
            for symbol_name, symbol_data in symbols.items():
                # ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö exact match ‡πÅ‡∏•‡∏∞ partial match
                if self._is_symbol_present(symbol_name, text_normalized):
                    # Calculate position for priority (earlier = higher priority)
                    position = text_normalized.find(symbol_name)
                    
                    symbols_found.append({
                        'name': symbol_name,
                        'category': category,
                        'data': symbol_data,
                        'position': position
                    })
        
        # Sort by position (earlier symbols first)
        symbols_found.sort(key=lambda x: x['position'])
        
        return symbols_found
    
    def _fix_thai_tokenization(self, text: str) -> str:
        """‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"""
        # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡∏ú‡∏¥‡∏î
        fixes = {
            '‡∏¢‡πà‡∏≤‡∏á': '‡∏≠‡∏¢‡πà‡∏≤‡∏á',  # ‡∏≠‡∏¢‡πà‡∏≤‡∏á -> ‡∏¢‡πà‡∏≤‡∏á
            '‡∏°‡πà‡∏ß‡∏¢‡∏î‡∏µ': '‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏î‡∏µ',
            '‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏≤‡∏¢': '‡∏™‡∏ö‡∏≤‡∏¢‡πÉ‡∏à',
            '‡∏Ç‡πà‡∏°‡∏Ç‡∏π‡πà': '‡∏Ñ‡∏∏‡∏Å‡∏Ñ‡∏≤‡∏°',
            '‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á': '‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢',
            '‡∏õ‡πà‡∏ß‡∏¢‡πÑ‡∏Ç‡πâ': '‡πÄ‡∏à‡πá‡∏ö‡∏õ‡πà‡∏ß‡∏¢',
            '‡∏ó‡πâ‡∏≠‡∏á‡∏ü‡πâ‡∏≤': '‡∏ü‡πâ‡∏≤',
            '‡∏ô‡πâ‡∏≥‡πÉ‡∏™': '‡∏ô‡πâ‡∏≥',
            '‡∏ô‡πâ‡∏≥‡∏Ç‡∏∏‡πà‡∏ô': '‡∏ô‡πâ‡∏≥'
        }
        
        text_fixed = text
        for wrong, correct in fixes.items():
            text_fixed = text_fixed.replace(wrong, correct)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡∏ú‡∏¥‡∏î‡πÄ‡∏õ‡πá‡∏ô "‡∏¢‡πà‡∏≤"
        import re
        
        # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç "‡∏≠‡∏¢‡πà‡∏≤‡∏á" ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô "‡∏¢‡πà‡∏≤‡∏á" 
        text_fixed = re.sub(r'\b‡∏¢‡πà‡∏≤‡∏á\b', '‡∏≠‡∏¢‡πà‡∏≤‡∏á', text_fixed)
        
        # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô
        common_fixes = [
            (r'\b‡∏°‡πà‡∏ß‡∏¢\b', '‡∏°‡∏µ'),           # "‡∏°‡∏µ" -> "‡∏°‡πà‡∏ß‡∏¢" 
            (r'\b‡∏Ñ‡πà‡∏ß‡∏¢\b', '‡∏Ñ‡∏¥‡∏ß'),          # "‡∏Ñ‡∏¥‡∏ß" -> "‡∏Ñ‡πà‡∏ß‡∏¢"
            (r'\b‡∏õ‡πà‡∏ß‡∏¢(?!‡πÑ‡∏Ç‡πâ)\b', '‡∏õ‡∏µ'),    # "‡∏õ‡∏µ" -> "‡∏õ‡πà‡∏ß‡∏¢" (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô "‡∏õ‡πà‡∏ß‡∏¢‡πÑ‡∏Ç‡πâ")
            (r'\b‡∏™‡πà‡∏ß‡∏¢\b', '‡∏™‡∏µ'),           # "‡∏™‡∏µ" -> "‡∏™‡πà‡∏ß‡∏¢"
            (r'\b‡∏•‡πà‡∏ß‡∏¢\b', '‡∏•‡∏µ'),           # "‡∏•‡∏µ" -> "‡∏•‡πà‡∏ß‡∏¢"
            (r'\b‡∏´‡πà‡∏ß‡∏¢\b', '‡∏´'),            # "‡∏´" -> "‡∏´‡πà‡∏ß‡∏¢"
            (r'\b‡∏ï‡πà‡∏ß‡∏¢\b', '‡∏ï‡∏µ'),           # "‡∏ï‡∏µ" -> "‡∏ï‡πà‡∏ß‡∏¢"
        ]
        
        for pattern, replacement in common_fixes:
            text_fixed = re.sub(pattern, replacement, text_fixed)
        
        return text_fixed
    
    def _is_symbol_present(self, symbol: str, text: str) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà - ‡πÅ‡∏ö‡∏ö‡∏â‡∏•‡∏≤‡∏î"""
        # Direct match
        if symbol in text:
            return True
        
        # Check for partial matches for compound symbols
        symbol_parts = symbol.split()
        if len(symbol_parts) > 1:
            # For multi-word symbols, check if all parts are present
            return all(part in text for part in symbol_parts)
        
        # Check for similar words (for single character differences)
        if len(symbol) > 2:
            import re
            # Create a pattern that allows for small variations
            pattern = re.escape(symbol)
            # Allow for one character difference
            if re.search(pattern, text):
                return True
        
        return False
    
    def _generate_interpretation(self, symbols_found: List[Dict], context: Dict) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°"""
        if not symbols_found:
            return "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ù‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏•‡∏∂‡∏Å‡∏•‡∏±‡∏ö ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÉ‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå"
        
        primary_symbol = symbols_found[0]
        interpretation = f"‡∏Å‡∏≤‡∏£‡∏ù‡∏±‡∏ô‡πÄ‡∏´‡πá‡∏ô{primary_symbol['name']}"
        
        # Add emotional context
        if 'fear' in context['emotions']:
            interpretation += "‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ß ‡∏≠‡∏≤‡∏à‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡πâ‡∏≤‡∏ó‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏∞‡πÄ‡∏ú‡∏ä‡∏¥‡∏ç"
        elif 'joy' in context['emotions']:
            interpretation += "‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç ‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏≤‡∏á‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ñ‡∏∂‡∏á‡πÇ‡∏ä‡∏Ñ‡∏•‡∏≤‡∏†"
        elif 'peaceful' in context['emotions']:
            interpretation += "‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏á‡∏ö ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏á‡∏ö‡∏™‡∏∏‡∏Ç‡πÉ‡∏ô‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï"
        
        # Add primary meaning
        interpretation += f" {primary_symbol['data']['meaning']}"
        
        # Add secondary symbols if any
        if len(symbols_found) > 1:
            secondary_symbols = [s['name'] for s in symbols_found[1:3]]
            interpretation += f" ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏°‡∏µ{', '.join(secondary_symbols)} ‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô"
        
        # Add size modifiers
        if 'huge' in context['size_modifiers']:
            interpretation += " ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡πÇ‡∏ï‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô"
        elif 'many' in context['size_modifiers']:
            interpretation += " ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∏‡∏î‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå"
        
        return interpretation
    
    def _predict_numbers_with_reasoning(self, symbols_found: List[Dict], context: Dict) -> List[Dict]:
        """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•"""
        predicted_numbers = []
        used_numbers = set()
        
        if not symbols_found:
            return self._get_default_numbers()
        
        primary_symbol = symbols_found[0]
        
        # Primary symbol numbers (highest confidence)
        main_combinations = primary_symbol['data']['combinations']
        for i, number in enumerate(main_combinations):
            if number not in used_numbers:
                confidence = 0.95 - (i * 0.05)  # Decreasing confidence
                predicted_numbers.append({
                    "number": number,
                    "score": round(confidence, 2),
                    "reason": f"‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå '{primary_symbol['name']}' ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡∏≥‡∏£‡∏≤"
                })
                used_numbers.add(number)
        
        # Mixed numbers from multiple symbols
        if len(symbols_found) > 1:
            for secondary_symbol in symbols_found[1:3]:
                # Create mixed combinations
                primary_main = primary_symbol['data']['main']
                secondary_main = secondary_symbol['data']['main']
                
                mixed_combinations = [
                    f"{primary_main}{secondary_main}",
                    f"{secondary_main}{primary_main}",
                ]
                
                for number in mixed_combinations:
                    if number not in used_numbers and len(predicted_numbers) < 8:
                        confidence = 0.85 - (len(predicted_numbers) * 0.03)
                        predicted_numbers.append({
                            "number": number,
                            "score": round(confidence, 2),
                            "reason": f"‡∏ú‡∏™‡∏°‡∏à‡∏≤‡∏Å '{primary_symbol['name']}' ‡πÅ‡∏•‡∏∞ '{secondary_symbol['name']}'"
                        })
                        used_numbers.add(number)
        
        # Context-modified numbers
        if 'fear' in context['emotions'] and len(predicted_numbers) < 8:
            # Add reversed numbers for fearful context
            for pred in predicted_numbers[:2]:
                reversed_num = pred['number'][::-1]
                if reversed_num not in used_numbers:
                    predicted_numbers.append({
                        "number": reversed_num,
                        "score": round(pred['score'] - 0.1, 2),
                        "reason": f"‡πÄ‡∏•‡∏Ç‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ß‡πÉ‡∏ô‡∏ù‡∏±‡∏ô"
                    })
                    used_numbers.add(reversed_num)
        
        # Size modifiers
        if 'huge' in context['size_modifiers']:
            # Boost confidence for existing numbers
            for pred in predicted_numbers[:3]:
                pred['score'] = min(0.98, pred['score'] + 0.05)
                pred['reason'] += " (‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡πÇ‡∏ï)"
        
        # Ensure we have at least 4 numbers
        while len(predicted_numbers) < 4:
            # Add secondary combinations from primary symbol
            symbol_data = symbols_found[0]['data']
            backup_numbers = [
                f"{symbol_data['main']}{symbol_data['main']}",
                f"{symbol_data['secondary']}{symbol_data['secondary']}",
                f"{symbol_data['main']}0",
                f"{symbol_data['secondary']}0"
            ]
            
            for number in backup_numbers:
                if number not in used_numbers and len(predicted_numbers) < 8:
                    predicted_numbers.append({
                        "number": number,
                        "score": round(0.70 - (len(predicted_numbers) * 0.02), 2),
                        "reason": f"‡πÄ‡∏•‡∏Ç‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå '{symbols_found[0]['name']}'"
                    })
                    used_numbers.add(number)
                    break
            else:
                break
        
        # Sort by confidence score
        predicted_numbers.sort(key=lambda x: x['score'], reverse=True)
        
        return predicted_numbers[:8]  # Return top 8 numbers
    
    def _handle_no_symbols_found(self, dream_text: str) -> Dict:
        """‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡πÉ‡∏ô‡∏ù‡∏±‡∏ô"""
        # Try to find numbers in text
        numbers_in_text = re.findall(r'\b\d{1,2}\b', dream_text)
        
        if numbers_in_text:
            predicted_numbers = []
            for i, num in enumerate(numbers_in_text[:4]):
                predicted_numbers.append({
                    "number": f"{int(num):02d}",
                    "score": round(0.75 - (i * 0.05), 2),
                    "reason": f"‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡πÉ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ù‡∏±‡∏ô‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á"
                })
            
            return {
                "interpretation": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÉ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ù‡∏±‡∏ô ‡πÅ‡∏ï‡πà‡∏û‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à ‡∏•‡∏≠‡∏á‡∏ô‡∏≥‡πÄ‡∏•‡∏Ç‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÇ‡∏ä‡∏Ñ‡∏î‡∏π",
                "main_symbols": [],
                "predicted_numbers": predicted_numbers
            }
        
        return self._get_default_numbers()
    
    def _get_default_numbers(self) -> Dict:
        """‡πÄ‡∏•‡∏Ç‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå"""
        default_numbers = [
            {"number": "07", "score": 0.60, "reason": "‡πÄ‡∏•‡∏Ç‡∏°‡∏á‡∏Ñ‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ù‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô"},
            {"number": "23", "score": 0.55, "reason": "‡πÄ‡∏•‡∏Ç‡πÅ‡∏´‡πà‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏´‡∏°‡πà"},
            {"number": "45", "score": 0.50, "reason": "‡πÄ‡∏•‡∏Ç‡πÅ‡∏´‡πà‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á"},
            {"number": "89", "score": 0.45, "reason": "‡πÄ‡∏•‡∏Ç‡πÅ‡∏´‡πà‡∏á‡∏û‡∏£‡∏∞‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏®‡∏±‡∏Å‡∏î‡∏¥‡πå‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå"}
        ]
        
        return {
            "interpretation": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ù‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏•‡∏∂‡∏Å‡∏•‡∏±‡∏ö ‡πÅ‡∏°‡πâ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏ö‡∏ß‡∏Å‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏™‡πà‡πÉ‡∏à",
            "main_symbols": [],
            "predicted_numbers": default_numbers
        }
    
    def _get_fallback_response(self, dream_text: str, error_msg: str) -> Dict:
        """Response ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î"""
        return {
            "interpretation": "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ù‡∏±‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á",
            "main_symbols": [],
            "predicted_numbers": [
                {"number": "07", "score": 0.50, "reason": "‡πÄ‡∏•‡∏Ç‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤"}
            ],
            "error": error_msg
        }