import feedparser
import requests
from django.core.management.base import BaseCommand
from django.utils import timezone
from django.utils.dateparse import parse_datetime
from django.db import transaction
from bs4 import BeautifulSoup
from ai_engine.models import DataSource, DataIngestionRecord
from news.models import NewsArticle, NewsCategory
# from news.news_analyzer import NewsAnalyzer  # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏ß‡∏¢ analyzer_switcher
import re
from datetime import datetime

class Command(BaseCommand):
    help = '‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å RSS feeds ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡∏£‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå'

    def add_arguments(self, parser):
        parser.add_argument(
            '--limit',
            type=int,
            default=20,
            help='‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏ï‡πà‡∏≠ feed ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏î‡∏∂‡∏á (default: 20)'
        )
        
        parser.add_argument(
            '--source',
            type=str,
            help='‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å DataSource ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ (‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠)'
        )

    def handle(self, *args, **options):
        limit = options['limit']
        source_name = options.get('source')
        
        self.stdout.write(
            self.style.SUCCESS(f'Starting RSS feed scraping (limit {limit} articles per source)')
        )
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î category ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        category, created = NewsCategory.objects.get_or_create(
            name='‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ',
            defaults={'slug': 'general', 'description': '‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏à‡∏≤‡∏Å RSS feeds'}
        )
        
        # ‡∏î‡∏∂‡∏á Data Sources
        if source_name:
            sources = DataSource.objects.filter(name__icontains=source_name, is_active=True)
        else:
            sources = DataSource.objects.filter(source_type='news', is_active=True)
        
        if not sources:
            self.stdout.write(
                self.style.WARNING('No active RSS feeds found')
            )
            return
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á analyzer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ç‡πà‡∏≤‡∏ß
        # analyzer = NewsAnalyzer()  # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏ß‡∏¢ analyzer_switcher
        from news.analyzer_switcher import AnalyzerSwitcher
        analyzer = AnalyzerSwitcher(preferred_analyzer='groq')
        
        total_processed = 0
        total_high_score = 0
        
        for source in sources:
            self.stdout.write(f'\nüì° ‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å: {source.name}')
            self.stdout.write(f'üîó URL: {source.url}')
            
            try:
                # ‡∏î‡∏∂‡∏á RSS feed
                feed = feedparser.parse(source.url)
                
                if feed.bozo:
                    self.stdout.write(
                        self.style.WARNING(f'‚ö†Ô∏è  RSS feed ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: {source.name}')
                    )
                    continue
                
                entries = feed.entries[:limit]
                self.stdout.write(f'üì∞ ‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß: {len(entries)} ‡∏Ç‡πà‡∏≤‡∏ß')
                
                source_processed = 0
                source_high_score = 0
                
                for entry in entries:
                    try:
                        with transaction.atomic():
                            # ‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡πà‡∏≤‡∏ß
                            title = entry.title
                            link = getattr(entry, 'link', '')
                            
                            # ‡∏î‡∏∂‡∏á content
                            content = self._extract_content(entry)
                            if len(content) < 50:  # ‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
                                continue
                            
                            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏ã‡πâ‡∏≥
                            if NewsArticle.objects.filter(title=title).exists():
                                continue
                            
                            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà
                            temp_article = type('TempArticle', (), {
                                'title': title,
                                'content': content
                            })()
                            
                            analysis = analyzer.analyze_article(temp_article)
                            
                            # ‡πÉ‡∏ä‡πâ Insight-AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
                            import sys
                            sys.path.insert(0, '/app/mcp_dream_analysis')
                            from specialized_django_integration import extract_news_numbers_for_django
                            
                            insight_result = extract_news_numbers_for_django(f"{title}\n\n{content}")
                            
                            # ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á 2 ‡∏£‡∏∞‡∏ö‡∏ö‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
                            has_news_numbers = analysis['numbers'] and len(analysis['numbers']) > 0
                            has_insight_entities = insight_result.get('extracted_entities') and len(insight_result.get('extracted_entities', [])) > 0
                            
                            if has_news_numbers and has_insight_entities:
                                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πà‡∏≤‡∏ß
                                article = NewsArticle.objects.create(
                                    title=title[:200],  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß
                                    content=content,
                                    intro=content[:500],
                                    category=category,
                                    source_url=link,
                                    status='published',
                                    published_date=timezone.now(),
                                    # ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà
                                    lottery_relevance_score=analysis['confidence'],
                                    lottery_category=analysis.get('category', 'general'),
                                    extracted_numbers=','.join(analysis['numbers'][:10]),
                                    confidence_score=analysis['confidence']
                                )
                                
                                source_processed += 1
                            else:
                                # ‡∏Ç‡πâ‡∏≤‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á 2 ‡∏£‡∏∞‡∏ö‡∏ö
                                if not has_news_numbers:
                                    self.stdout.write(f'‚è≠Ô∏è ‡∏Ç‡πâ‡∏≤‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç (AI Analyzer): {title[:50]}...')
                                elif not has_insight_entities:
                                    self.stdout.write(f'‚è≠Ô∏è ‡∏Ç‡πâ‡∏≤‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç (Insight-AI): {title[:50]}...')
                                else:
                                    self.stdout.write(f'‚è≠Ô∏è ‡∏Ç‡πâ‡∏≤‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç: {title[:50]}...')
                                continue
                            
                            # ‡∏ô‡∏±‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á
                            if analysis['confidence'] >= 80:
                                source_high_score += 1
                                self.stdout.write(
                                    self.style.SUCCESS(
                                        f'üéØ ‡∏Ç‡πà‡∏≤‡∏ß‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á: {title[:50]}... '
                                        f'(‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {analysis["confidence"]}, ‡∏´‡∏°‡∏ß‡∏î: {analysis["category"]})'
                                    )
                                )
                            elif analysis['confidence'] >= 60:
                                self.stdout.write(f'* {title[:50]}... (Score: {analysis["confidence"]})')
                            else:
                                self.stdout.write(f'üì∞ {title[:50]}... (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {analysis["confidence"]})')
                            
                            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô DataIngestionRecord
                            DataIngestionRecord.objects.create(
                                data_source=source,
                                raw_content=f"{title}\\n{content}",
                                processed_content=content,
                                title=title,
                                extracted_numbers=analysis['numbers'],
                                relevance_score=analysis['confidence'],
                                processing_status='completed'
                            )
                            
                    except Exception as e:
                        self.stdout.write(
                            self.style.ERROR(f'Error: {entry.title[:30]}... - {str(e)}')
                        )
                        continue
                
                # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
                source.last_scraped = timezone.now()
                source.save()
                
                total_processed += source_processed
                total_high_score += source_high_score
                
                self.stdout.write(
                    f'OK {source.name}: {source_processed} articles (High score: {source_high_score})'
                )
                
            except Exception as e:
                self.stdout.write(
                    self.style.ERROR(f'Error at {source.name}: {str(e)}')
                )
                continue
        
        # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        self.stdout.write('\n' + '='*50)
        self.stdout.write(
            self.style.SUCCESS(f'üéØ ‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!')
        )
        self.stdout.write(f'üì∞ ‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_processed} ‡∏Ç‡πà‡∏≤‡∏ß')
        self.stdout.write(f'üî• ‡∏Ç‡πà‡∏≤‡∏ß‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á (‚â•80): {total_high_score} ‡∏Ç‡πà‡∏≤‡∏ß')
        
        if total_high_score > 0:
            percentage = (total_high_score / total_processed) * 100 if total_processed > 0 else 0
            self.stdout.write(
                self.style.SUCCESS(f'üìä ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ç‡πà‡∏≤‡∏ß‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û: {percentage:.1f}%')
            )
        
        # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà
        self._show_category_stats()
    
    def _extract_content(self, entry):
        """‡∏™‡∏Å‡∏±‡∏î‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å RSS entry"""
        content = ''
        
        # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ content ‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ï‡πà‡∏≤‡∏á‡πÜ
        if hasattr(entry, 'content'):
            content = entry.content[0].value if entry.content else ''
        elif hasattr(entry, 'summary'):
            content = entry.summary
        elif hasattr(entry, 'description'):
            content = entry.description
        
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î HTML
        if content:
            soup = BeautifulSoup(content, 'html.parser')
            content = soup.get_text().strip()
            
            # ‡∏•‡∏ö whitespace ‡πÄ‡∏Å‡∏¥‡∏ô
            content = re.sub(r'\\s+', ' ', content)
            
        return content or '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏î‡πâ'
    
    def _show_category_stats(self):
        """‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà"""
        from django.db.models import Count
        
        stats = NewsArticle.objects.values('lottery_category').annotate(
            count=Count('id')
        ).order_by('-count')
        
        if stats:
            self.stdout.write('\\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà:')
            category_names = {
                'accident': 'üî• ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏ï‡∏∏',
                'celebrity': '* Celebrity',
                'economic': 'üìà ‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à',
                'general': 'üì∞ ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ'
            }
            
            for stat in stats:
                category = stat['lottery_category']
                count = stat['count']
                name = category_names.get(category, category)
                self.stdout.write(f'  {name}: {count} ‡∏Ç‡πà‡∏≤‡∏ß')