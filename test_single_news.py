# -*- coding: utf-8 -*-
import os
import sys
import django
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
import json

# --- Setup Django ---
sys.path.append('/app')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'lekdedai.settings')
django.setup()

from news.models import NewsArticle, NewsCategory
from lekdedai.utils import generate_unique_slug
from django.utils import timezone

# --- Setup Gemini ---
api_key = "AIzaSyAjivjnnUo2AL5v4HGVkC4mTIH4kxMyOPU"
genai.configure(api_key=api_key)
model = genai.GenerativeModel('gemini-1.5-flash-8b')  # ‡πÉ‡∏ä‡πâ Flash Lite ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î quota

def _clean_website_junk(content):
    """‡∏•‡∏ö‡∏Ç‡∏¢‡∏∞‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    import re
    
    if not content:
        return ""
    
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏Ç‡∏¢‡∏∞‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡πâ‡∏ô ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏£‡∏¥‡∏á
    if any(keyword in content[:300].lower() for keyword in ['logo', 'thairath', '‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å', 'light', 'dark', '‡∏ü‡∏±‡∏á‡∏Ç‡πà‡∏≤‡∏ß']):
        # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏£‡∏¥‡∏á
        start_markers = ['‡∏≠‡∏î‡∏µ‡∏ï‡∏ô‡∏≤‡∏¢‡∏Å‡∏£‡∏±‡∏ê‡∏°‡∏ô‡∏ï‡∏£‡∏µ', '‡∏ô‡∏≤‡∏¢‡∏Å‡∏£‡∏±‡∏ê‡∏°‡∏ô‡∏ï‡∏£‡∏µ', '‡∏ó‡∏±‡∏Å‡∏©‡∏¥‡∏ì ‡∏ä‡∏¥‡∏ô‡∏ß‡∏±‡∏ï‡∏£', '‡∏ó‡∏±‡∏Å‡∏©‡∏¥‡∏ì', '‡∏£‡∏≠‡∏á‡∏ô‡∏≤‡∏¢‡∏Å', '‡∏£‡∏±‡∏ê‡∏°‡∏ô‡∏ï‡∏£‡∏µ']
        for marker in start_markers:
            if marker in content:
                start_pos = content.find(marker)
                if start_pos > 50:  # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡∏¢‡∏∞‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 50 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤
                    content = content[start_pos:]
                    break
    
    return content.strip()

def scrape_thairath_news(url):
    """Scrape ‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å Thairath URL"""
    print(f"üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á scrape ‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å: {url}")
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ‡∏´‡∏≤ title
        title_elem = soup.find('h1') or soup.find('title')
        title = title_elem.get_text(strip=True) if title_elem else '‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å Thairath'
        
        # ‡∏´‡∏≤ content
        content_selectors = [
            '.entry-content', '.post-content', '.article-content',
            'article', '.content', 'main'
        ]
        
        content = ""
        for selector in content_selectors:
            elem = soup.select_one(selector)
            if elem:
                # ‡∏•‡∏ö script, style tags
                for tag in elem(['script', 'style', 'nav', 'footer', 'aside']):
                    tag.decompose()
                content = elem.get_text(separator=' ', strip=True)
                break
        
        if not content:
            # fallback ‡πÉ‡∏ä‡πâ body
            body = soup.find('body')
            if body:
                for tag in body(['script', 'style', 'nav', 'footer', 'aside']):
                    tag.decompose()
                content = body.get_text(separator=' ', strip=True)
        
        print(f"‚úÖ Scrape ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(content)} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£")
        
        # Clean content ‡∏Å‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å - ‡∏•‡∏ö‡∏Ç‡∏¢‡∏∞‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏≠‡∏≠‡∏Å
        cleaned_content = _clean_website_junk(content.strip())
        
        return {
            'title': title.strip(),
            'content': cleaned_content[:2000],  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î 2000 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
            'url': url
        }
        
    except Exception as e:
        print(f"‚ùå Error scraping: {e}")
        return None

def analyze_with_gemini(title, content):
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏î‡πâ‡∏ß‡∏¢ Gemini Flash Lite"""
    print("ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ Gemini...")
    
    prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏ï‡∏µ‡πÄ‡∏•‡∏Ç‡∏´‡∏ß‡∏¢‡πÑ‡∏ó‡∏¢ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡∏µ‡πâ‡∏´‡∏≤‡πÄ‡∏•‡∏Ç‡πÄ‡∏î‡πá‡∏î:

‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {title}
‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {content}

‚ö†Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å: ‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏£‡∏ñ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡πÄ‡∏î‡πá‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î! ‡∏´‡∏≤‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏£‡∏ñ‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ
‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: "‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô", "‡∏£‡∏ñ‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô", "‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô" ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö "‡∏Å‡∏Ç-1234", "‡∏û‡∏£-195" 

‡∏´‡∏≤‡πÄ‡∏•‡∏Ç‡∏à‡∏≤‡∏Å:
1. ‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏£‡∏ñ (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!) - ‡πÄ‡∏ä‡πà‡∏ô "‡∏û‡∏£ 195" ‚Üí ‡πÄ‡∏•‡∏Ç 195, 19, 95
2. ‡∏≠‡∏≤‡∏¢‡∏∏‡∏Ñ‡∏ô - ‡πÄ‡∏ä‡πà‡∏ô "‡∏≠‡∏≤‡∏¢‡∏∏ 25 ‡∏õ‡∏µ" ‚Üí ‡πÄ‡∏•‡∏Ç 25
3. ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏ - ‡πÄ‡∏ä‡πà‡∏ô "‡πÄ‡∏ß‡∏•‡∏≤ 9.09" ‚Üí ‡πÄ‡∏•‡∏Ç 09
4. ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏î‡∏µ - ‡πÄ‡∏ä‡πà‡∏ô "‡∏Ñ‡∏î‡∏µ‡∏ä‡∏±‡πâ‡∏ô 14" ‚Üí ‡πÄ‡∏•‡∏Ç 14
5. ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô/‡∏Ñ‡∏ô - ‡πÄ‡∏ä‡πà‡∏ô "5 ‡∏•‡πâ‡∏≤‡∏ô" ‚Üí ‡πÄ‡∏•‡∏Ç 5

‡∏´‡πâ‡∏≤‡∏°: 
- ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà (‡πÄ‡∏ä‡πà‡∏ô 9 ‡∏Å.‡∏¢., ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 12), ‡∏õ‡∏µ ‡∏û.‡∏®. (‡πÄ‡∏ä‡πà‡∏ô 2568)
- ‡πÄ‡∏•‡∏Ç‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô: ‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏Ç‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
{{
  "is_relevant": true,
  "category": "politics",
  "relevance_score": 85,
  "extracted_numbers": [
    {{
      "number": "195",
      "source": "‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏£‡∏ñ ‡∏û‡∏£ 195",
      "confidence": 95
    }},
    {{
      "number": "19",
      "source": "‡∏à‡∏≤‡∏Å‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô ‡∏û‡∏£ 195 (19)",
      "confidence": 90
    }},
    {{
      "number": "95",
      "source": "‡∏à‡∏≤‡∏Å‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô ‡∏û‡∏£ 195 (95)",
      "confidence": 90
    }}
  ],
  "reasoning": "‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏£‡∏ñ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡πÄ‡∏î‡πá‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡∏µ‡πâ"
}}
"""
    
    try:
        response = model.generate_content(prompt)
        result_text = response.text.strip()
        
        print(f"üìù Gemini Response: {result_text[:500]}...")  # ‡πÄ‡∏û‡∏¥‡πà‡∏° debug
        
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î JSON
        if result_text.startswith('```json'):
            result_text = result_text[7:]
        if result_text.endswith('```'):
            result_text = result_text[:-3]
        result_text = result_text.strip()
        
        try:
            result = json.loads(result_text)
            
            # ‡∏£‡∏ß‡∏ö‡πÄ‡∏•‡∏Ç‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô (‡πÑ‡∏°‡πà‡∏™‡∏ô‡πÉ‡∏à reasoning ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô)
            detailed_numbers = result.get('extracted_numbers', [])
            unique_numbers = {}
            
            for item in detailed_numbers:
                number = item['number']
                source = item['source'] 
                confidence = item['confidence']
                
                # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏Ç‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡πÅ‡∏ï‡πà confidence ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤
                if number not in unique_numbers or confidence > unique_numbers[number]['confidence']:
                    unique_numbers[number] = {
                        'number': number,
                        'source': source,  # ‡πÉ‡∏ä‡πâ source ‡∏ó‡∏µ‡πà‡∏°‡∏µ confidence ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
                        'confidence': confidence
                    }
                elif confidence == unique_numbers[number]['confidence'] and len(source) < len(unique_numbers[number]['source']):
                    # ‡∏ñ‡πâ‡∏≤ confidence ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô ‡πÉ‡∏ä‡πâ source ‡∏ó‡∏µ‡πà‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤ (‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡∏Å‡∏ß‡πà‡∏≤)
                    unique_numbers[number]['source'] = source
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô list ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° confidence
            final_numbers = list(unique_numbers.values())
            final_numbers.sort(key=lambda x: x['confidence'], reverse=True)
            
            return {
                'success': True,
                'is_relevant': result.get('is_relevant', False),
                'category': result.get('category', 'other'),
                'relevance_score': result.get('relevance_score', 0),
                'numbers': [item['number'] for item in final_numbers],
                'detailed_numbers': final_numbers,
                'reasoning': result.get('reasoning', ''),
                'raw_response': result_text
            }
        except json.JSONDecodeError as e:
            print(f"‚ùå JSON Parse Error: {e}")
            return {
                'success': False,
                'error': 'Invalid JSON response',
                'raw_response': result_text
            }
            
    except Exception as e:
        error_msg = str(e)
        if "quota" in error_msg.lower() or "429" in error_msg:
            print(f"‚ùå API Quota ‡∏´‡∏°‡∏î: {e}")
            print("‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô - ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ Mock Analyzer")
            return {
                'success': False,
                'error': 'QUOTA_EXCEEDED',
                'message': 'Gemini API quota exceeded'
            }
        else:
            print(f"‚ùå Gemini API Error: {e}")
            return {
                'success': False,
                'error': str(e)
            }

def save_to_database(news_data, analysis):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πà‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    print("üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    
    # ‡∏´‡∏≤/‡∏™‡∏£‡πâ‡∏≤‡∏á category
    category_name = {
        'politics': '‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á',
        'accident': '‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏ï‡∏∏', 
        'crime': '‡∏≠‡∏≤‡∏ä‡∏ç‡∏≤‡∏Å‡∏£‡∏£‡∏°',
        'celebrity': '‡∏Ñ‡∏ô‡∏î‡∏±‡∏á',
        'other': '‡∏≠‡∏∑‡πà‡∏ô‡πÜ'
    }.get(analysis.get('category', 'other'), '‡∏≠‡∏∑‡πà‡∏ô‡πÜ')
    
    category, created = NewsCategory.objects.get_or_create(
        name=category_name,
        defaults={
            'slug': analysis.get('category', 'other'),
            'description': f'‡∏Ç‡πà‡∏≤‡∏ß{category_name}‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ Gemini AI'
        }
    )
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á slug
    slug = generate_unique_slug(NewsArticle, news_data['title'], None)
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πà‡∏≤‡∏ß
    article = NewsArticle.objects.create(
        title=news_data['title'],
        slug=slug,
        category=category,
        intro=news_data['content'][:300] + '...' if len(news_data['content']) > 300 else news_data['content'],
        content=news_data['content'],
        extracted_numbers=','.join(analysis['numbers'][:15]),
        confidence_score=min(analysis.get('relevance_score', 50), 100),
        lottery_relevance_score=analysis.get('relevance_score', 50),
        lottery_category=analysis.get('category', 'other'),
        status='published',
        published_date=timezone.now(),
        source_url=news_data['url'],
        
        # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Gemini analysis
        insight_summary=analysis.get('reasoning', ''),
        insight_impact_score=analysis.get('relevance_score', 0) / 100,
        insight_entities=[
            {
                'value': item['number'],
                'entity_type': 'number',
                'reasoning': item['source'],
                'significance_score': item['confidence'] / 100
            } for item in analysis.get('detailed_numbers', [])
        ]
    )
    
    print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {article.title}")
    print(f"üîó URL: http://localhost:8000{article.get_absolute_url()}")
    
    return article

def main():
    url = "https://www.thairath.co.th/news/politic/2881640"  # URL ‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏±‡∏Å‡∏©‡∏¥‡∏ì
    
    print("=== ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß‡∏î‡πâ‡∏ß‡∏¢ Gemini Flash Lite ===")
    print()
    
    # 1. Scrape ‡∏Ç‡πà‡∏≤‡∏ß
    news_data = scrape_thairath_news(url)
    if not news_data:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ scrape ‡∏Ç‡πà‡∏≤‡∏ß‡πÑ‡∏î‡πâ")
        return
    
    print(f"üì∞ ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {news_data['title']}")
    print(f"üìù ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {len(news_data['content'])} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£")
    print()
    
    # 2. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ Gemini
    analysis = analyze_with_gemini(news_data['title'], news_data['content'])
    
    if not analysis['success']:
        if analysis.get('error') == 'QUOTA_EXCEEDED':
            print("‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å quota ‡∏´‡∏°‡∏î")
            return
        else:
            print(f"‚ùå ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {analysis.get('error', 'Unknown error')}")
            return
    
    if not analysis.get('is_relevant') or not analysis.get('numbers'):
        print("‚ö†Ô∏è ‡∏Ç‡πà‡∏≤‡∏ß‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏´‡∏ß‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏•‡∏Ç‡πÄ‡∏î‡πá‡∏î")
        return
    
    print("‚úÖ ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:")
    print(f"   üî¢ ‡πÄ‡∏•‡∏Ç: {', '.join(analysis['numbers'])}")
    print(f"   üìä ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {analysis.get('relevance_score', 0)}/100")
    print(f"   üìÇ ‡∏´‡∏°‡∏ß‡∏î: {analysis.get('category', 'other')}")
    print(f"   üí° ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•: {analysis.get('reasoning', '')[:100]}...")
    print()
    
    # 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    try:
        article = save_to_database(news_data, analysis)
        print()
        print("üéâ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î!")
        print(f"üì∞ ‡∏Ç‡πà‡∏≤‡∏ß: {article.title}")
        print(f"üî¢ ‡πÄ‡∏•‡∏Ç‡πÄ‡∏î‡πá‡∏î: {article.extracted_numbers}")
        print(f"üåê ‡∏î‡∏π‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà: http://localhost:8000{article.get_absolute_url()}")
        
    except Exception as e:
        print(f"‚ùå Error saving to database: {e}")

if __name__ == "__main__":
    main()