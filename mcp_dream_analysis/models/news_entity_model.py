"""
AI Model #2: The News Extractor (NewsEntity_Model) 
à¹€à¸‰à¸žà¸²à¸°à¸—à¸²à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸ªà¸à¸±à¸” Entity à¸•à¸±à¸§à¹€à¸¥à¸‚à¸ˆà¸²à¸à¸‚à¹ˆà¸²à¸§ (Named Entity Recognition)
"""
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, precision_recall_fscore_support
import joblib
import os
import re
from typing import List, Dict, Tuple, Optional, Set
from datetime import datetime
import json
from dataclasses import dataclass

try:
    from pythainlp import word_tokenize, sent_tokenize
    from pythainlp.util import normalize
    PYTHAINLP_AVAILABLE = True
except ImportError:
    PYTHAINLP_AVAILABLE = False

@dataclass
class EntitySpan:
    """Class to represent an entity span"""
    text: str
    start: int
    end: int
    entity_type: str
    confidence: float

class NewsEntityModel:
    """
    AI Model à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸à¸±à¸” Numerical Entities à¸ˆà¸²à¸à¸‚à¹ˆà¸²à¸§
    à¹€à¸‰à¸žà¸²à¸°à¸—à¸²à¸‡à¸”à¹‰à¸²à¸™ Named Entity Recognition (NER)
    """
    
    def __init__(self, model_path: Optional[str] = None):
        self.model_path = model_path or "news_entity_model.pkl"
        
        # Feature extractors for different entity types
        self.feature_extractors = {}
        self.entity_classifiers = {}
        
        # Supported entity types
        self.entity_types = [
            'license_plate',    # à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¸£à¸–
            'age',             # à¸­à¸²à¸¢à¸¸  
            'house_number',    # à¸šà¹‰à¸²à¸™à¹€à¸¥à¸‚à¸—à¸µà¹ˆ
            'quantity',        # à¸ˆà¸³à¸™à¸§à¸™/à¸›à¸£à¸´à¸¡à¸²à¸“
            'date',            # à¸§à¸±à¸™à¸—à¸µà¹ˆ
            'time',            # à¹€à¸§à¸¥à¸²
            'lottery_number',  # à¹€à¸¥à¸‚à¸¥à¸­à¸•à¹€à¸•à¸­à¸£à¸µà¹ˆ
            'phone_number',    # à¹€à¸šà¸­à¸£à¹Œà¹‚à¸—à¸£à¸¨à¸±à¸žà¸—à¹Œ
            'id_number',       # à¹€à¸¥à¸‚à¸šà¸±à¸•à¸£à¸›à¸£à¸°à¸Šà¸²à¸Šà¸™
        ]
        
        self.is_trained = False
        self.training_metrics = {}
        
        # Initialize patterns and rules
        self.entity_patterns = self._init_entity_patterns()
        self.context_patterns = self._init_context_patterns()
    
    def _init_entity_patterns(self) -> Dict[str, List[str]]:
        """Initialize regex patterns for each entity type"""
        return {
            'license_plate': [
                r'[à¸-à¸®]{1,2}\s*[\d]{1,4}',  # Thai license plate
                r'[\d]{2,4}',               # Numbers in license context
                r'[A-Z]{1,3}[\d]{1,4}',     # English prefix + numbers
            ],
            
            'age': [
                r'(?:à¸­à¸²à¸¢à¸¸|à¸›à¸µ)\s*[\d]{1,3}',
                r'[\d]{1,3}\s*(?:à¸‚à¸§à¸š|à¸›à¸µ|à¹€à¸”à¸·à¸­à¸™)',
                r'(?:à¸§à¸±à¸¢)\s*[\d]{1,3}',
            ],
            
            'house_number': [
                r'(?:à¸šà¹‰à¸²à¸™à¹€à¸¥à¸‚à¸—à¸µà¹ˆ|à¹€à¸¥à¸‚à¸—à¸µà¹ˆ|à¸«à¸¡à¸¹à¹ˆà¸—à¸µà¹ˆ)\s*[\d]{1,6}',
                r'[\d]{1,6}\s*(?:/[\d]{1,3})?',  # House number with sub-number
                r'(?:à¸¡\.)\s*[\d]{1,2}',          # à¸«à¸¡à¸¹à¹ˆ abbreviation
            ],
            
            'quantity': [
                r'[\d]{1,10}\s*(?:à¸šà¸²à¸—|à¸à¸´à¹‚à¸¥à¸à¸£à¸±à¸¡|à¸à¸´à¹‚à¸¥|à¸à¸\.|à¸•à¸±à¸§|à¸„à¸™|à¹ƒà¸š|à¸­à¸±à¸™)',
                r'[\d,]{1,15}\s*(?:à¸šà¸²à¸—)',
                r'[\d]{1,8}\s*(?:à¸„à¸™|à¸„à¸£à¸­à¸šà¸„à¸£à¸±à¸§)',
            ],
            
            'date': [
                r'[\d]{1,2}[\/\-.][\d]{1,2}[\/\-.]([\d]{2,4})',
                r'(?:à¸§à¸±à¸™à¸—à¸µà¹ˆ)\s*[\d]{1,2}',
                r'[\d]{1,2}\s*(?:à¸¡à¸à¸£à¸²à¸„à¸¡|à¸à¸¸à¸¡à¸ à¸²à¸žà¸±à¸™à¸˜à¹Œ|à¸¡à¸µà¸™à¸²à¸„à¸¡|à¹€à¸¡à¸©à¸²à¸¢à¸™|à¸žà¸¤à¸©à¸ à¸²à¸„à¸¡|à¸¡à¸´à¸–à¸¸à¸™à¸²à¸¢à¸™|à¸à¸£à¸à¸Žà¸²à¸„à¸¡|à¸ªà¸´à¸‡à¸«à¸²à¸„à¸¡|à¸à¸±à¸™à¸¢à¸²à¸¢à¸™|à¸•à¸¸à¸¥à¸²à¸„à¸¡|à¸žà¸¤à¸¨à¸ˆà¸´à¸à¸²à¸¢à¸™|à¸˜à¸±à¸™à¸§à¸²à¸„à¸¡)',
            ],
            
            'time': [
                r'[\d]{1,2}[:\.][\d]{2}\s*(?:à¸™\.|à¸™à¸²à¸¬à¸´à¸à¸²)',
                r'(?:à¹€à¸§à¸¥à¸²)\s*[\d]{1,2}[:\.][\d]{2}',
                r'[\d]{1,2}\s*(?:à¹‚à¸¡à¸‡|à¸™à¸²à¸¬à¸´à¸à¸²)',
            ],
            
            'lottery_number': [
                r'[\d]{6}',  # 6-digit lottery numbers
                r'[\d]{3}\s*[\d]{3}',
                r'(?:à¸£à¸²à¸‡à¸§à¸±à¸¥à¸—à¸µà¹ˆ)\s*[\d]{1,6}',
            ],
            
            'phone_number': [
                r'[\d]{3}[-\s][\d]{3}[-\s][\d]{4}',
                r'[\d]{10}',
                r'(?:à¹‚à¸—à¸£|à¹€à¸šà¸­à¸£à¹Œ)\s*[\d\-\s]{8,15}',
            ],
            
            'id_number': [
                r'[\d]{1}-[\d]{4}-[\d]{5}-[\d]{2}-[\d]{1}',
                r'[\d]{13}',
                r'(?:à¹€à¸¥à¸‚à¸›à¸£à¸°à¸ˆà¸³à¸•à¸±à¸§|à¸šà¸±à¸•à¸£à¸›à¸£à¸°à¸Šà¸²à¸Šà¸™)\s*[\d\-]{10,20}',
            ],
        }
    
    def _init_context_patterns(self) -> Dict[str, List[str]]:
        """Initialize context patterns that help identify entities"""
        return {
            'license_plate': [
                'à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¸£à¸–', 'à¸£à¸–à¸¢à¸™à¸•à¹Œ', 'à¸£à¸–à¸ˆà¸±à¸à¸£à¸¢à¸²à¸™à¸¢à¸™à¸•à¹Œ', 'à¸›à¹‰à¸²à¸¢à¸—à¸°à¹€à¸šà¸µà¸¢à¸™', 
                'à¸‚à¸±à¸šà¸£à¸–', 'à¸£à¸–à¸„à¸±à¸™à¸™à¸µà¹‰', 'à¸‚à¹‰à¸²à¸¡', 'à¸ˆà¸­à¸”', 'à¸§à¸´à¹ˆà¸‡'
            ],
            
            'age': [
                'à¸­à¸²à¸¢à¸¸', 'à¸›à¸µ', 'à¸‚à¸§à¸š', 'à¸§à¸±à¸¢', 'à¹€à¸”à¹‡à¸', 'à¸œà¸¹à¹‰à¹ƒà¸«à¸à¹ˆ', 'à¸„à¸™à¹à¸à¹ˆ',
                'à¹€à¸à¸´à¸”', 'à¹à¸à¹ˆ', 'à¹€à¸¢à¸²à¸§à¹Œ', 'à¸§à¸±à¸¢à¸£à¸¸à¹ˆà¸™'
            ],
            
            'house_number': [
                'à¸šà¹‰à¸²à¸™à¹€à¸¥à¸‚à¸—à¸µà¹ˆ', 'à¹€à¸¥à¸‚à¸—à¸µà¹ˆ', 'à¸«à¸¡à¸¹à¹ˆà¸—à¸µà¹ˆ', 'à¸•à¸³à¸šà¸¥', 'à¸­à¸³à¹€à¸ à¸­', 'à¸ˆà¸±à¸‡à¸«à¸§à¸±à¸”',
                'à¸­à¸¢à¸¹à¹ˆ', 'à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆ', 'à¸šà¹‰à¸²à¸™', 'à¸«à¸¡à¸¹à¹ˆà¸šà¹‰à¸²à¸™', 'à¸‹à¸­à¸¢', 'à¸–à¸™à¸™'
            ],
            
            'quantity': [
                'à¸šà¸²à¸—', 'à¸à¸´à¹‚à¸¥à¸à¸£à¸±à¸¡', 'à¸à¸´à¹‚à¸¥', 'à¸•à¸±à¸§', 'à¸„à¸™', 'à¹ƒà¸š', 'à¸­à¸±à¸™',
                'à¸ˆà¸³à¸™à¸§à¸™', 'à¸›à¸£à¸´à¸¡à¸²à¸“', 'à¸£à¸²à¸„à¸²', 'à¹€à¸‡à¸´à¸™', 'à¸„à¹ˆà¸²', 'à¸•à¹‰à¸™à¸—à¸¸à¸™'
            ],
            
            'date': [
                'à¸§à¸±à¸™à¸—à¸µà¹ˆ', 'à¹€à¸¡à¸·à¹ˆà¸­', 'à¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆ', 'à¸ˆà¸™à¸–à¸¶à¸‡', 'à¹ƒà¸™', 'à¸Šà¹ˆà¸§à¸‡',
                'à¹€à¸”à¸·à¸­à¸™', 'à¸›à¸µ', 'à¸§à¸±à¸™', 'à¹€à¸à¸´à¸”à¹€à¸«à¸•à¸¸'
            ],
            
            'time': [
                'à¹€à¸§à¸¥à¸²', 'à¸™à¸²à¸¬à¸´à¸à¸²', 'à¹‚à¸¡à¸‡', 'à¸™à¸²à¸—à¸µ', 'à¸§à¸´à¸™à¸²à¸—à¸µ',
                'à¸•à¸­à¸™', 'à¸Šà¹ˆà¸§à¸‡', 'à¹€à¸¡à¸·à¹ˆà¸­', 'à¹€à¸§à¸¥à¸²'
            ],
        }
    
    def extract_entities_with_patterns(self, text: str) -> Dict[str, List[str]]:
        """Extract entities using regex patterns and context"""
        results = {entity_type: [] for entity_type in self.entity_types}
        
        text_normalized = normalize(text) if PYTHAINLP_AVAILABLE else text.lower()
        
        for entity_type in self.entity_types:
            patterns = self.entity_patterns.get(entity_type, [])
            context_words = self.context_patterns.get(entity_type, [])
            
            for pattern in patterns:
                matches = re.finditer(pattern, text_normalized, re.IGNORECASE)
                
                for match in matches:
                    matched_text = match.group().strip()
                    start, end = match.span()
                    
                    # Check context (50 chars before and after)
                    context_start = max(0, start - 50)
                    context_end = min(len(text_normalized), end + 50)
                    context = text_normalized[context_start:context_end]
                    
                    # Calculate context relevance
                    context_score = sum(1 for word in context_words if word in context.lower())
                    
                    # Extract just the number parts
                    numbers = re.findall(r'\d+', matched_text)
                    
                    for number in numbers:
                        if self._is_valid_entity(number, entity_type):
                            results[entity_type].append({
                                'value': number,
                                'full_match': matched_text,
                                'context_score': context_score,
                                'position': (start, end)
                            })
        
        # Remove duplicates and sort by context score
        for entity_type in results:
            seen = set()
            filtered = []
            
            # Sort by context score (descending)
            results[entity_type].sort(key=lambda x: x['context_score'], reverse=True)
            
            for item in results[entity_type]:
                if item['value'] not in seen:
                    seen.add(item['value'])
                    filtered.append(item['value'])
            
            results[entity_type] = filtered[:5]  # Keep top 5
        
        return results
    
    def _is_valid_entity(self, number: str, entity_type: str) -> bool:
        """Validate extracted numbers based on entity type"""
        if not number.isdigit():
            return False
        
        num_len = len(number)
        
        validation_rules = {
            'license_plate': lambda n: 1 <= len(n) <= 4,
            'age': lambda n: 1 <= int(n) <= 120 and len(n) <= 3,
            'house_number': lambda n: 1 <= len(n) <= 6,
            'quantity': lambda n: 1 <= len(n) <= 10,
            'date': lambda n: len(n) <= 4,  # Year, day, month
            'time': lambda n: len(n) <= 2,   # Hour, minute
            'lottery_number': lambda n: len(n) == 6,
            'phone_number': lambda n: len(n) == 10,
            'id_number': lambda n: len(n) == 13,
        }
        
        validator = validation_rules.get(entity_type, lambda n: True)
        return validator(number)
    
    def extract_features_for_training(self, text: str, entities: Dict[str, List]) -> np.ndarray:
        """Extract features for training the ML models"""
        features = []
        
        # Text statistics
        features.extend([
            len(text),
            len(text.split()),
            text.count('\d') if hasattr(text, 'count') else 0,
        ])
        
        # Entity pattern matches
        for entity_type in self.entity_types:
            patterns = self.entity_patterns.get(entity_type, [])
            total_matches = 0
            
            for pattern in patterns:
                matches = len(re.findall(pattern, text, re.IGNORECASE))
                total_matches += matches
            
            features.append(total_matches)
        
        # Context word presence
        for entity_type in self.entity_types:
            context_words = self.context_patterns.get(entity_type, [])
            context_count = sum(1 for word in context_words if word.lower() in text.lower())
            features.append(context_count)
        
        return np.array(features)
    
    def prepare_training_data(self, news_data: List[Dict]) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:
        """Prepare training data for all entity types"""
        features = []
        targets = {entity_type: [] for entity_type in self.entity_types}
        
        for data in news_data:
            text = data['news_content']
            entities = data.get('entities', {})
            
            # Extract features
            text_features = self.extract_features_for_training(text, entities)
            features.append(text_features)
            
            # Create targets (binary classification for each entity type)
            for entity_type in self.entity_types:
                has_entity = 1 if entities.get(entity_type) and len(entities[entity_type]) > 0 else 0
                targets[entity_type].append(has_entity)
        
        return np.array(features), {k: np.array(v) for k, v in targets.items()}
    
    def train(self, news_data: List[Dict], test_size: float = 0.2):
        """Train all entity recognition models"""
        print("ðŸ” à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¸à¸¶à¸à¸ªà¸­à¸™ NewsEntity_Model...")
        
        # Prepare data
        X, y_dict = self.prepare_training_data(news_data)
        
        print(f"ðŸ“Š à¸ˆà¸³à¸™à¸§à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”: {X.shape[0]} samples")
        print(f"ðŸ“Š à¸ˆà¸³à¸™à¸§à¸™ features: {X.shape[1]}")
        
        # Split data
        X_train, X_test, _, _ = train_test_split(X, X, test_size=test_size, random_state=42)
        
        # Train individual classifiers for each entity type
        self.training_metrics = {}
        
        for entity_type in self.entity_types:
            print(f"ðŸŽ¯ à¸à¸¶à¸à¸ªà¸­à¸™à¸•à¸±à¸§à¸ˆà¸³à¹à¸™à¸: {entity_type}...")
            
            y = y_dict[entity_type]
            y_train, y_test, _, _ = train_test_split(
                y, y, test_size=test_size, random_state=42, stratify=y
            )
            
            # Choose classifier based on entity type
            if entity_type in ['license_plate', 'lottery_number']:
                classifier = RandomForestClassifier(n_estimators=100, random_state=42)
            else:
                classifier = LogisticRegression(random_state=42, max_iter=1000)
            
            # Train
            classifier.fit(X_train, y_train)
            
            # Evaluate
            y_pred = classifier.predict(X_test)
            
            precision, recall, f1, _ = precision_recall_fscore_support(
                y_test, y_pred, average='weighted', zero_division=0
            )
            
            self.entity_classifiers[entity_type] = classifier
            self.training_metrics[entity_type] = {
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'accuracy': classifier.score(X_test, y_test)
            }
            
            print(f"   âœ… {entity_type}: F1={f1:.3f}, Accuracy={self.training_metrics[entity_type]['accuracy']:.3f}")
        
        self.is_trained = True
        
        # Overall metrics
        overall_f1 = np.mean([metrics['f1'] for metrics in self.training_metrics.values()])
        overall_accuracy = np.mean([metrics['accuracy'] for metrics in self.training_metrics.values()])
        
        print(f"âœ… à¸à¸²à¸£à¸à¸¶à¸à¸ªà¸­à¸™à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™!")
        print(f"ðŸ“ˆ F1-Score à¸£à¸§à¸¡: {overall_f1:.3f}")
        print(f"ðŸ“ˆ Accuracy à¸£à¸§à¸¡: {overall_accuracy:.3f}")
        
        return self.training_metrics
    
    def predict(self, news_content: str) -> Dict[str, List[str]]:
        """Extract entities from news content"""
        # Start with pattern-based extraction
        pattern_results = self.extract_entities_with_patterns(news_content)
        
        # If models are trained, use ML to refine results
        if self.is_trained:
            features = self.extract_features_for_training(news_content, {}).reshape(1, -1)
            
            ml_results = {}
            for entity_type in self.entity_types:
                if entity_type in self.entity_classifiers:
                    classifier = self.entity_classifiers[entity_type]
                    
                    # Predict if this entity type is present
                    has_entity = classifier.predict(features)[0]
                    confidence = classifier.predict_proba(features)[0][1] if hasattr(classifier, 'predict_proba') else 0.5
                    
                    if has_entity and confidence > 0.3:
                        # Keep pattern results if ML says entity is present
                        ml_results[entity_type] = pattern_results.get(entity_type, [])
                    else:
                        # Filter out or reduce pattern results
                        ml_results[entity_type] = pattern_results.get(entity_type, [])[:2]  # Keep only top 2
                else:
                    ml_results[entity_type] = pattern_results.get(entity_type, [])
            
            return ml_results
        else:
            # Return pattern-based results only
            return pattern_results
    
    def save_model(self, filepath: Optional[str] = None):
        """Save the trained model"""
        filepath = filepath or self.model_path
        
        model_data = {
            'entity_classifiers': self.entity_classifiers,
            'entity_patterns': self.entity_patterns,
            'context_patterns': self.context_patterns,
            'entity_types': self.entity_types,
            'is_trained': self.is_trained,
            'training_metrics': self.training_metrics,
            'timestamp': datetime.now().isoformat(),
            'model_type': 'NewsEntity_Model',
            'version': '1.0.0'
        }
        
        joblib.dump(model_data, filepath)
        print(f"ðŸ’¾ NewsEntity_Model à¸šà¸±à¸™à¸—à¸¶à¸à¹à¸¥à¹‰à¸§: {filepath}")
    
    def load_model(self, filepath: Optional[str] = None):
        """Load a trained model"""
        filepath = filepath or self.model_path
        
        if not os.path.exists(filepath):
            print(f"âš ï¸  à¹„à¸¡à¹ˆà¸žà¸šà¹„à¸Ÿà¸¥à¹Œà¹‚à¸¡à¹€à¸”à¸¥: {filepath}")
            return False
        
        try:
            model_data = joblib.load(filepath)
            
            self.entity_classifiers = model_data.get('entity_classifiers', {})
            self.entity_patterns = model_data.get('entity_patterns', self.entity_patterns)
            self.context_patterns = model_data.get('context_patterns', self.context_patterns)
            self.entity_types = model_data.get('entity_types', self.entity_types)
            self.is_trained = model_data.get('is_trained', False)
            self.training_metrics = model_data.get('training_metrics', {})
            
            print(f"âœ… NewsEntity_Model à¹‚à¸«à¸¥à¸”à¸ªà¸³à¹€à¸£à¹‡à¸ˆ: {filepath}")
            print(f"ðŸ“Š à¹€à¸§à¸­à¸£à¹Œà¸Šà¸±à¸™: {model_data.get('version', 'Unknown')}")
            
            return True
            
        except Exception as e:
            print(f"âŒ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹‚à¸«à¸¥à¸” NewsEntity_Model: {str(e)}")
            return False
    
    def get_model_info(self) -> Dict:
        """Get model information"""
        return {
            'model_name': 'NewsEntity_Model',
            'model_type': 'Named Entity Recognition (NER)',
            'version': '1.0.0',
            'is_trained': self.is_trained,
            'training_metrics': self.training_metrics,
            'entity_types': self.entity_types,
            'features': {
                'pattern_based': True,
                'ml_enhanced': self.is_trained,
                'pythainlp_available': PYTHAINLP_AVAILABLE
            },
            'supported_languages': ['thai'],
            'capabilities': [
                'numerical_entity_extraction',
                'context_awareness',
                'pattern_matching',
                'ml_classification'
            ]
        }